*refs
https://github.com/yihong-chen/neural-collaborative-filtering/blob/master/src/data.py
https://github.com/yihong-chen/neural-collaborative-filtering/blob/master/src/train.py
https://github.com/rdevooght/sequence-based-recommendations

[전처리로 생성하는 파일]
- train: (user, item)의 형태로 positive instance만 담고 있는 리스트
- movie: item set

[Dataset]
- __init__(): user, item, labels 보관용

[SampleGenerator]
- epoch마다 negative sampling해서 self.user, self.item, self.labels 생성

- dataset 생성, dataloader 생성해서 반환함.

- 생성자에서 파일 한 번만 로드해서 멤버 변수로 저장해두니 로딩 시간은 걱정 안 해도 됨.

[hyperparameter tuning]
- train mode일 시 지정된 모델에 대해 config를 갖고 tuning함.

- config의 각 hp조합에 대하여 train_tuning으로 학습하고 매 epoch마다 validset으로 hr, loss 계산.

- best hr일 때마다 best hp 업데이트

- 결국 각 hp조합마다 best hr을 구하고 그 best hr들의 best인 hp가 최종 best hp

- best hp를 갖고 test 실행: 재학습은 하지 않음

[best model]
- train / valid / test set 나누기

- 하이퍼파라미터 조합을 바꿔가며 trainset으로 학습 후 validset으로 검증 반복

- validset에 대해 best performance가 나온 순간(특정 HP, epoch)의 model A 저장 => 해당 model A에 바로 testset 적용하고 결과 기록

- @A의 HP를 최적의 HP로 삼고, 더 많은 trainset으로 학습시키기 위해 trainset + validset 합쳐서 trainset으로 만들고
  처음부터 다시 학습한다면 언제 학습을 종료해야할까? 전체 trainset에 대한 loss 최소인 때의 모델로 최종 학습된 모델 결정?
  => trainset에 대한 최소 loss or 최대 acc가 testset에 대해서도 best일 거라는 보장 없음. 오히려 trainset에 overfitting된 모델 탄생.
  => 결국 미지의 set이 더이상 없으므로 testset을 쓰지 않는 이상 epoch 중에서 언제가 generally 최적의 학습된 상태인지 알 방법이 없음.
  => 따라서 model A에 바로 testset 적용하는게 맞는 듯.